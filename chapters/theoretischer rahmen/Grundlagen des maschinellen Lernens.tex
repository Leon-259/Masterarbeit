\section{Grundlagen des maschinellen Lernens} \label{sec:Grundlagen ML}
Traditionelle Computerprogramme bestehen aus einer Abfolge von Befehlen, welche dem Computer Schritt für Schritt erklären, was er tun soll. \glsdisp{ML}{Lern-Algorithmen} sind in der Lage eigenständig herauszufinden, was sie tun sollen. \Gls{ML} hat seine Anfänge in den 1950er Jahren. Seither wurde eine Vielzahl an Ansätzen entwickelt, um Maschinen Lernfähigkeit zu verleihen. Diese reichen von einfachen statistischen Modellen bis hin zu komplexen neuronalen Netzen. Heutzutage ist \gls{ML} fester Bestandteil unseres Alltags. Sei es durch Empfehlungsalgorithmen beim Online-Shopping, durch Spam-Filter für das E-Mail Postfach, in der Überwachung von öffentlichen Räumen durch \gls{MOT} oder durch den neusten Trend: Large Language Modells wie \textit{ChatGPT} \cite{Domingos.2015, Liu.2023}. Die Geschichte des \gls{ML} zeigt, dass für Computer oftmals die Aufgaben am herausforderndsten sind, welche Menschen intuitiv bewältigt werden können. Es ist schwierig einem Computer den Lösungsweg für solche Aufgaben zu erklären \cite{Goodfellow.2016}. \par

In \cite{Mitchell.1997} wird \gls{ML} beschrieben, als ein Lernprozess, welcher ein Computer automatisch durchführt. Es wird wie folgt definiert: Ein Computerprogramm ist Lernfähig, wenn es sich durch Erfahrung \(E\) in seiner Performance \(P\) im Bezug auf die Bewältigung einer Aufgabe \(A\) verbessert. In einem Beispiel möchte ein Autohändler den Verkaufswert von Autos schätzen. Dazu muss er zunächst auswählen, welche Eigenschaften eines Autos er für die Schätzung nutzen möchte. Er entscheidet sich für die Anzahl der gefahrenen Kilometer und das Alter des Autos. Solche Eigenschaften werden \gls{Feature}[s] genannt. \gls{Feature}[s] sind Merkmale, welche Informationen zur Bewältigung der Aufgabe \(A\) beisteuern. Die \gls{Feature}[s] werden in einer \gls{Datenmatrix} \(\nommat{X}\) angeordnet. Bezogen auf das Beispiel beinhalten die Spalten in \(\nommat{X}\) die Werte der gefahrenen Kilometer und des Alters der Autos. Die Zeilen von \(X\) beinhalten die \gls{Feature}[s] zu jeweils einem Auto. Neben der \gls{Datenmatrix} benötigen viele Modelle noch einen \gls{Zielvektor} \(\nomvec{y}\). Dieser Beinhaltet die Ziel-Werte für die Aufgabe A. Im Beispiel ist jedes Element \(\nomvec{y}_i\) der Wert eines Autos. Jede Reihe \(\nommat{X}_{i,:}\) beinhaltet die Informationen zu der Anzahl der gefahrenen Kilometer und des Alters von einem spezifischen Auto. Aus diesem Grund wird eine Zeile \(\nommat{X}_{i,:}\) auch \gls{Featurevektor} genannt. Das Element \(\nomvec{y}_i\) ist der Wert für den dieses spezifische Auto verkauft wurde. Zusammen bilden \(\nommat{X}\) und \(\nomvec{y}\) einen Datensatz. Dieser Datensatz ist die Erfahrung \(E\) mit dessen Hilfe das Programm lernen soll. Hat der Autohändler \(N=20\) Erfahrungswerte so ist der Datensatz Aufgebaut aus \(N\) Datenpunkten \(D = \{(\nommat{X}_{i,:}, \nomvec{y}_i)\}_{i}^{N}\) \cite{Goodfellow.2016, Burkov.2019, ShalevShwartz.2014}. Die Tabelle \ref{tab:BspMLAuto} zeigt den Aufbau des Datensatzes aus dem Beispiel. 


\begin{table}
    \centering
    \begin{tabular}{|r|r|r|}
     \hline
        Verkaufswert in €   & gefahrene Kilometer   & Alter in Jahren\\
     \hline
        10200               & 52000                 & 5             \\
     \hline
        7100                & 140000                & 12            \\
     \hline
        \vdots              & \vdots                & \vdots        \\
     \hline
         23800              & 25000                 & 2             \\
      \hline
    \end{tabular}
    \caption{Aufbau des Datensatzes für das Beispiel der Schätzung von Verkaufswerten von Autos. Die Spalte \textit{Verkaufswerte} entspricht \(\nomvec{y}\). Die Spalten \textit{gefahrene Kilometer} und \textit{Alter in Jahren} bilden \(\nommat{X}\). }
    \label{tab:BspMLAuto}
\end{table}

Damit ist die Aufgabe \(A\) und die Erfahrung \(E\) für das Beispiel definiert. 

\begin{itemize}
    \item A: Schätzung des Verkaufswerts von Autos.
    \item E: Datensatz aus den \gls{Feature}[s] und den \glsdisp{Zielvektor}{Zielwerten}.
\end{itemize}

\emptyFigure{Beispiel einer \glsdisp{ML}{maschinellen Lernaufgabe}. Schätzung vom Verkaufswerten von Autos. Auf der y-Achse sind ist der \glsdisp{Zielvektor}{Zielwert} dargestellt. Auf der y-Achse ist das \gls{Feature} \textit{Anzahl der gefahrenen Kilometer} abgebildet. Die Werte der Achsen sind Normiert.}{fig:BspMLAuto}

Die Abbildung \ref{fig:BspMLAuto} zeigt die die Punkte in \(D\) für den \glsdisp{Zielvektor}{Zielwert} und das \gls{Feature} \textit{Anzahl der gefahrenen Kilometer}. Um ein Lernfähiges Programm zu erhalten muss eine mathematische Repräsentation für die Bewältigung der Aufgabe \(A\) gefunden werden. Durch diese mathematische Repräsentation, ist die Performance \(P\) des Programms bewertbar \cite{Mitchell.1997}. Ein einfacher Algorithmus für \gls{ML} ist die lineare Regression. Diese wird für das Problem des Autohändlers durchgeführt. Für eine linearen Regression wird die Repräsentation aus \ref{eq:linReg} für die Lösung von \(A\) gewählt.

\begin{equation}
    \label{eq:linReg}
    \hat{y}(\nomvec{w}, \nomvec{x}) =  \nomvecT{w}\nomvec{x} = w_1x_1 + w_2x_2 + \dots + w_nx_n
\end{equation}

Der vom Programm geschätzte Wert eines Autos ist \(\hat{y}(\nomvec{w}, \nomvec{x})\). Der Vektor \(\nomvec{x}\) ist ein \gls{Featurevektor} und er beinhaltet die Werte der \gls{Feature}[s] zu einem Auto. Der Vektor \(\nomvecT{w}\) beinhaltet Gewichte für die \gls{Feature}[s]. Für die Schätzung von \(\hat{y}(\nomvec{w}, \nomvec{x})\) wird somit jeder \gls{Feature}[wert] \(\nomvec{x}_i\) mit einem Parameter \(\nomvecT{w}_i\) gewichtet, welcher den Einfluss des \gls{Feature}[s] \(\nomvec{x}_i\) beschreibt \cite{Goodfellow.2016}. Die Gewichte \(\nomvecT{w}\) werden \gls{Modellparameter} genannt. Allgemein ausgedrückt sind \gls{Modellparameter} das, was ein Programm bei einem \gls{Modelltraining}{Trainingsprozess} versucht zu lernen \cite{Zheng.2015}. \par

Mit dieser mathematischen Repräsentation lässt sich eine Formulierung zur Beurteilung der Performance \(P\) finden. Diese ist mit Hilfe der Erfahrung \(E\) zu ermitteln. Für eine Probe \(\nommat{X}_{i:}\) aus \(\nommat{X}\) lässt sich mit der linearen Regression ein Schätzwert \(\hat{y}(\nomvec{w}, \nommat{X}_{i:})\) berechnen. Der Fehler des Programms ist über die Differenz zum echten Wert \(\nomvec{y}_i\) bestimmbar. Um die Performance \(P\) des Modells zu bewerten wird der  \glsdisp{MSE}{mittlere quadratische Fehler (MSE)} von allen Proben \(N\) im Datensatz \(D\) berechnet. Die Berechnung des \gls{MSE} ist in \ref{eq:MSE} zu sehen \cite{Goodfellow.2016, Burkov.2019}.

\begin{equation}
    \label{eq:MSE}
    MSE = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i(\nomvec{w}, \nommat{X}_{i:}) - \nomvec{y}_i)_i^2
\end{equation}

Die Formulierung \((\hat{y}_i(\nomvec{w}, \nommat{X}_{i:}) - \nomvec{y}_i)^2\) wird als \gls{Verlustfunktion} bezeichnet. Jedes Modell des \glsdisp{ML}{maschinellen Lernens} besitzt ein \gls{Verlustfunktion}. Die in \ref{eq:MSE} verwendete \gls{Verlustfunktion} wird als quadratische \gls{Verlustfunktion} bezeichnet. Der \gls{MSE} ist hier eine \gls{Zielfunktion} für ein Optimierungsproblem. Der \gls{MSE} soll minimal werden. Dies ist in \ref{eq:minMSE} formuliert \cite{Goodfellow.2016, Burkov.2019}.

\begin{equation}
    \label{eq:minMSE}
    \underset{w}{\arg\min} \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i(\nomvec{w}, \nommat{X}_{i:}) - \nomvec{y}_i)_i^2
\end{equation}

Die Lösung von \ref{eq:minMSE} resultiert in optimalen Gewichten \(\nomvec{w}\), um \(\hat{y}(\nomvec{w}, \nomvec{x})\) möglichst genau zu Schätzen. Das Lösen von \ref{eq:minMSE} ist der \glsdisp{ML}{Lernprozess} des Programms. Dieser wird mit einer Optimierungsroutine umgesetzt. Häufig verwendet wird das \gls{Gradientenverfahren}. Bei diesem wird wie folgt vorgegangen. Alle Parameter \(\nomvec{w}^{(t)}\) erhalten einen initial Wert für den Startzeitpunkt \(t=1\), bspw. \(\nomvec{w}_i^{(1)}=0 \forall i\). Für die \gls{Zielfunktion} wird der Gradient berechnet \(\nabla MSE(\nomvec{w}^{(t)})\). Iterativ wird nun in Richtung des steilsten Abstieges des Gradienten gegangen. Da der Gradient in Richtung des steilsten Anstieges zeigt, wird in die negative Richtung des Gradienten gegangen. Die Werte von \(\nomvec{w}\) werden bei jedem Schritt aktualisiert \cite{Mitchell.1997, Goodfellow.2016, ShalevShwartz.2014}. Dies zeigt die Formulierung \ref{eq:GradDecentUpdateW}.

\begin{equation}
    \label{eq:GradDecentUpdateW}
    \nomvec{w}^{(t+1)} \leftarrow \nomvec{w}^{(t)} - \eta\nabla MSE(\nomvec{w}^{(t)})
\end{equation}

Der Parameter \(\eta\) wird dabei als Lernrate bezeichnet. Die Lernrate bestimmt die Schrittgröße, welche bei jeder Iteration in Richtung des steilsten Abstiegs gegangen wird \cite{Mitchell.1997}. Die Lernrate ist vom Anwender einzustellen. Parameter, welche vom Anwender festzulegen sind werden \gls{Hyperparameter} gennant. Sie sind nicht zu verwechseln mit den \gls{Modellparameter}[n] \cite{Zheng.2015}. Bei einem Minimum gilt \(\nabla MSE(\nomvec{w}^{(t)}) = 0\). Verändern sich die Werte von \(\nomvec{w}^{(t)}\) durch weiterer Iterationen nicht mehr, wurde ein Minimum gefunden \cite{Goodfellow.2016, Burkov.2019}. Die Abbildung \ref{fig:GradDecentBsp} veranschaulicht die Suche des Minimums durch das \gls{Gradientenverfahren}.

\emptyFigure{Fehlt. }{fig:GradDecentBsp}
\todo{Abbildung fehlt}

Mit diesem vorgehen ist auch das Beispiel des Autohändlers lösbar. Um das Beispiel anschaulich zu halten, wird das Modell der lineare Regression aus \ref{eq:linReg} nur mit dem \gls{Feature} der Anzahl der gefahrenen Kilometer trainiert. Die Abbildung \ref{fig:BspMLAutoMitReg} zeigt die gleichen Datenpunkte dar, wie die Abbildung \ref{fig:BspMLAuto}, jedoch ist nun die resultierende Gerade \(\hat{y}(x)\) eingezeichnet. 

\emptyFigure{Die Abbildung zeigt Datenpunkte von verkauften Autos. Auf der y-Achse sind die Verkaufspreise dargestellt. Auf der x-Achse ist die Anzahl der gefahrenen Kilometer zu sehen. Beide Achsen sind Normiert. Eingezeichnet ist eine Gerade. Die Gerade wurde durch eine lineare Regression ermittelt.}{fig:BspMLAutoMitReg}
\todo{Abbildung fehlt}

Das Beispiel der linearen Regression zeigt, dass sich die Bestandteile eines Algorithmus für \gls{ML} allgemein wie folgt zusammenfassen lassen \cite{Burkov.2019, Mitchell.1997, Goodfellow.2016}.

\begin{enumerate}
    \item \textbf{Definition einer Aufgabe:} Eine Aufgabe muss definiert werden, welche durch \gls{ML} gelöst werden soll. Für diese Aufgabe muss eine mathematische Repräsentation gefunden werden.
    \item \textbf{Definition einer \gls{Verlustfunktion}:} Um die Performance des Algorithmus zu bewerten, ist eine \gls{Verlustfunktion} zu definieren.
    \item \textbf{Definition einer \gls{Zielfunktion}:} Die \gls{Verlustfunktion} ist in ein Optimierungsproblem zu überführen, für welches eine \gls{Zielfunktion} zu formulieren ist.
    \item \textbf{Definition einer Optimierungsroutine:} Um das Optimierungsproblem der \gls{Zielfunktion} zu lösen wird ein Algorithmus benötigt, welcher das gesuchte Optimum findet. Für die Berechnung wird Erfahrung benötigt in Form eines Datensatzes.
\end{enumerate}


\section{Klassifizierung und Regression}
Die Aufgaben, für welche \gls{ML} am häufigsten verwendet wird sind Regression und \gls{Klassifikation}. In \ref{sec:Grundlagen ML} wurde der Algorithmus der linearen Regression angewendet um ein Regressionsproblem zu lösen. Bei der Regression wird ein Zielwert \(\hat{y}(\nomvec{x}) \in \mathbb{R}\) geschätzt. Wobei \(\nomvec{x}\) der \gls{Feature}[vektor] einer Probe ist. Der Datensatz, mit welchem das Modell \glsdisp{Modelltraining}{trainiert} wird besteht aus einer \gls{Datenmatrix} \(\nommat{X}\), welche \gls{Feature}[werte] beinhaltet und einem \gls{Zielvektor} \(\nomvec{y}\), welcher die korrekten Zielwerte zu den Proben der \gls{Datenmatrix} beinhaltet. Für \(\nomvec{y}\) gilt ebenfalls \(\nomvec{y}_i \in \mathbb{R} \forall i \) \cite{Burkov.2019, ShalevShwartz.2014}. \par

Bei der \gls{Klassifikation} soll ein Modell unbekannte Proben einer Klasse zuordnen. Anstatt eines reelen Zielwerts soll für \(\hat{y}(\nomvec{x})\) eine Klassenzugehörigkeit geschätzt werden. Als Ergebnis vergibt ein \glsdisp{Klassifikation}{Klassifikator} einer Probe ein \gls{Label}, welches die Klassenzugehörigkeit deutlich macht. Der Vektor \(\nomvec{y}\) wird deshalb für \glsdisp{Klassifikation}{Klassifizierungsprobleme} meistens als \gls{Labelvektor} bezeichnet. Im folgenden wird der Begriff \gls{Zielvektor} als allgemeine Form verwendet. Ein klassisches Beispiel für ein \glsdisp{Klassifikation}{Klassifizierungsproblem} ist ein Spam-Filter für das E-Mail Postfach. Dieser ordnet neu eintreffende E-Mails entweder in die Klasse \textit{Kein Spam}, oder in die Klasse \textit{Spam} ein \cite{Burkov.2019}. \par

In dem Beispiel des Spam-Filters handelt es sich um binäre \gls{Klassifikation}. Das Modell muss nur zwischen zwei Klassen unterscheiden können. Ein weiteres Beispiel wäre ein Arzt, der seine Patienten in die Klassen \textit{Gesund} und \textit{Krank} einteilt. Es gibt jedoch auch Aufgaben bei denen zwischen mehr als zwei Klassen unterschieden werden muss. Solche Aufgaben werden als \gls{Mehrklassen Klassifizierung} bezeichnet. Ein Beispiel für \gls{Mehrklassen Klassifizierung} wäre wieder der Arzt, welcher für seine kranken Patienten von einem Modell direkt das passende Medikament empfohlen bekommen möchte. Die \gls{Datenmatrix} enthält \gls{Feature}[s] zu den Symptomen und Unverträglichkeiten der Patienten. Der \gls{Labelvektor} enthält die Bezeichnungen für die Medikamente, welche den Patienten am meisten geholfen haben. Jedes Element im \gls{Labelvektor} erhält eins er folgenden \gls{Label}[s] \(\nomvec{y}_i \in \{Ibuprofen, Paracetamol, Diclofenac\}\). Einige Modelle sind dazu in der Lage \gls{Mehrklassen Klassifizierung}[saufgaben] unmittelbar von sich aus zu lösen. Andere Modelle sind nur zu binärer \gls{Klassifikation} fähig \cite{Burkov.2019}.\par

\gls{Mehrklassen Klassifizierung}[saufgaben] sind jedoch auch von Modellen lösbar, welche nur binär \glsdisp{Klassifikation}{klassifizieren} können. Dafür existieren zwei Strategien. 

\textbf{One versus All}\par
Bei dieser Strategie werden mehrere binäre \glsdisp{Klassifikation}{Klassifikatoren} trainiert, die jeweils eine Klasse von den Restlichen unterscheiden. Bezogen auf das Beispiel des Arztes würden drei \glsdisp{Klassifikation}{Klassifikatoren} trainiert werden, welche wie folgt unterschieden werden.

\begin{enumerate}
    \item \(Ibuprofen\) gegen \(Paracetamol, Diclofenac\)
    \item \(Paracetamol\) gegen \(Ibuprofen, Diclofenac\)
    \item \(Diclofenac\) gegen \(Paracetamol, Ibuprofen\)
\end{enumerate}

Wenn für einen Patienten \(Ibuprofen\) die beste Wahl ist, gibt der \glsdisp{Klassifikation}{Klassifikator} Nummer 1. eine Bestätigung zurück und die anderen beiden \glsdisp{Klassifikation}{Klassifikatoren} eine Verneinung. So ist die Klassenzugehörigkeit eindeutig zu bestimmen \cite{Bishop.2006, ShalevShwartz.2014}. \par

\textbf{One versus One}\par
Bei dieser Strategie werden ebenfalls mehrere binäre \glsdisp{Klassifikation}{Klassifikatoren} trainiert. Diesmal jedoch paarweise. Für das Beispiel des Arztes resultieren folgende \glsdisp{Klassifikation}{Klassifikatoren}.

 \begin{enumerate}
     \item \(Ibuprofen\) gegen \(Paracetamol\)
     \item \(Ibuprofen\) gegen \(Diclofenac\)
     \item \(Paracetamol\) gegen \(Diclofenac\)
 \end{enumerate}

 Die Klassenzugehörigkeit ist für diese Strategie über eine Mehrheitsentscheidung bestimmt. Ist \(Ibuprofen\) die beste Wahl laut \glsdisp{Klassifikation}{Klassifikator} Nummer 1. und auch laut \glsdisp{Klassifikation}{Klassifikator} Nummer 2., ist die Klassenzugehörigkeit zu \(Ibuprofen\) bestimmt


\subsection{Kategorisierung von Algorithmen für maschinelles Lernen}
Sowie sich Aufgaben von Algorithmen für \gls{ML} in Regression und \gls{Klassifikation} unterteilen lassen, so existieren weiter Kategorien, mit welchen sich solche Algorithmen unterscheiden lassen. \par

\textbf{\Gls{überwachtes Lernen} und \gls{unüberwachtes Lernen}:}\\
Algorithmen für \gls{ML} können sich in ihrer Lernstrategie unterschieden. Die wichtigsten Strategien sind das \glsdisp{überwachtes Lernen}{überwachte Lernen} und das \glsdisp{unüberwachtes Lernen}{unüberwachte Lernen}. Ein Beispiel für \gls{überwachtes Lernen} ist das Beispiel des Autohändlers aus \ref{sec:Grundlagen ML}. Das lineare Regressionsmodell wird mit einem Datensatz trainiert, welcher sich aus einer \gls{Datenmatrix} und einem \gls{Zielvektor} zusammensetzt. Jede Probe im Datensatz besitzt durch den \gls{Zielvektor} ein korrektes Ergebnis, über welches der Algorithmus lernt, wie ein korrektes Ergebnis aussieht. Ein Überwachung findet in dem Sinne statt, dass der Anwender über den \gls{Zielvektor} Einfluss darauf nehmen kann, was der Algorithmus lernt \cite{Burkov.2019, Goodfellow.2016}.\par

Beim \glsdisp{unüberwachtes Lernen}{unüberwachten Lernen} wird kein \gls{Zielvektor} verwendet. Der Algorithmus lernt nur durch die \gls{Datenmatrix} Muster in den Daten. Dieser Ansatz findet oft in der Clusteranalyse Anwendung. Dabei versucht ein Algorithmus selbstständig Gruppen im Datensatz zu finden, nur basierend auf der Lage der Proben im \gls{Feature}[raum]. Der Anwender hat keine Möglichkeit über einen \gls{Zielvektor} Einfluss auf den Lernprozess zu nehmen \cite{Burkov.2019, Goodfellow.2016}. \par

\textbf{Modellbasiertes Lernen und instanzbasiertes Lernen:}\\
Die meisten Algorithmen arbeiten modellbasiert. Das bedeutet durch einen Lernprozess wird versucht eine explizite \gls{Zielfunktion} zu finden, welche die Aufgabe löst. Im Beispiel des Autohändlers aus \ref{sec:Grundlagen ML} wird die explizite \gls{Zielfunktion} einer linearen Regression erlernt. Dazu nutzt der Algorithmus einen Datensatz. Ist die \gls{Zielfunktion} gefunden, wird dieser nicht mehr benötigt \cite{Burkov.2019}.\par

Beim instanzbasierten Lernen wird stattdessen der gesamte Datensatz gespeichert. Über die Position der Trainingsproben im \gls{Feature}[raum] lassen sich unbekannte Proben evaluieren. Ein Beispiel hierfür ist die \textit{Nächste Nachbarn Klassifikation}. Soll mittels diesem \glsdisp{Klassifikation}{Klassifikators} die Klassenzugehörigkeit einer unbekannten Probe bestimmt werden, dann betrachtet der Algorithmus die umliegenden Trainingsproben. Die Klasse, welche unter den umliegenden  Trainingsproben am häufigsten Auftritt ist auch die Klasse der unbekannten Probe \cite{Burkov.2019, Mitchell.1997}.\par

\textbf{\gls{Deep Learning} und \gls{ML}:}\\
Die Begriffe \gls{ML} und \gls{Deep Learning} stehen in einem hierarchischen Zusammenhang. \Gls{ML} umfasst alle Lernalgorithmen. Dazu zählen einfache Algorithmen wie die lineare Regression, sowie Komplexe Modelle wie sie im Bereich des \gls{Deep Learning} zu finden sind. \gls{Deep Learning} ist somit eine spezielle Art des \glsdisp{ML}{maschinellen Lernens}. Diesen Zusammenhang visualisiert die Abbildung \ref{fig:zusammenhangDL_ML} \cite{Goodfellow.2016, Burkov.2019}.

\emptyFigure{Das Diagramm zeigt, dass \gls{Deep Learning} ein Teilgebiet des \glsdisp{ML}{maschinellen Lernens} ist. Sie sind in der Wissenschaft der künstlichen Intelligenz verordnet.}{fig:zusammenhangDL_ML}
\todo{Abbildung fehlt}

\gls{Deep Learning} Modelle sind aus mehreren Schichten aufgebaut. Die Schichten sind aus einfachen Algorithmen des \glsdisp{ML}{maschinellen Lernens} aufgebaut. Eine Schicht bekommt als Eingabe die Ausgabe der vorausgegangenen Schicht. Dadurch werden die meisten Modellparameter nicht durch den Datensatz direkt trainiert, sondern durch die Ausgabe der vorausgegangenen Schichten. Aus diesem Grund sind \gls{Deep Learning} Modelle auch deutlich besser in der Lage mit Rohdaten zu arbeiten, als einfachere Modell. Durch die Schichten sind sie in der Lage selbstständig \gls{Feature}[s] zu extrahieren. Eine Schicht ist aufgebaut aus Einheiten. Jede Einheit ist ein einfaches Modell, wie bspw. die lineare Regression. Durch die Schichtung solcher einfacher Modelle lassen sich sehr komplexe Muster in Daten finden. Die Abbildung \ref{fig:SimpleDL} zeigt den Aufbau eines einfachen \gls{Deep Learning} Netzwerks \cite{Burkov.2019, Goodfellow.2016}. 

\emptyFigure{Fehlt.}{fig:SimpleDL}
\todo{Abbildung fehlt}

\textbf{Weitere Unterscheidungsmerkmale:}\\
Algorithmen können sich in der Menge an Daten unterscheiden, welche im Training benötigt wird um passende Modellparameter zu finden. Ebenfalls ist der Rechenaufwand für das Training von Modell zu Modell unterschiedlich hoch. Hierbei besteht auch ein Zusammenhang mit den Modellparametern. Umso mehr Modellparameter optimiert werden müssen, desto höher ist der Aufwand. Ein weiterer rechenaufwendiger Prozess ist die Suche nach optimalen \gls{Hyperparameter}[n]. Auch hier gilt, umso mehr Hyperparamter zu konfigurieren sind, desto Aufwändiger ist die Suche. Auch die Implementierung kann unterschiedlich Aufwendig sein. In der Praxis werden Algorithmen für \gls{ML} jedoch selten selst Programmiert. In den meisten fällen werden Software-\gls{Bibliothek}[en] verwendet, welche die Algorithmen implementieren. Allgemein ist es so, dass komplexe Modelle, wie im \gls{Deep Learning} höhere Anforderungen an die Datenmenge und die Rechenleistung haben, als einfache Modelle des \glsdisp{ML}{maschinellen Lernens} \cite{Burkov.2019, ShalevShwartz.2014}. 