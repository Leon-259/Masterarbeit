% This file was created with Citavi 6.14.0.0

@proceedings{.2006,
 year = {2006}
}


@misc{Allan.2023,
 abstract = {trackpy v0.6.1 is functionally equivalent to v0.6.0. It is being released to fix an issue with Zenodo, so that this trackpy release has a citable DOI.

See the {\textless}a href={\textquotedbl}http://soft-matter.github.io/trackpy/v0.6.0/whatsnew.html{\textquotedbl}{\textgreater}release notes for v0.6.0 for more information.},
 author = {Allan, Daniel B. and Caswell, Thomas and Keim, Nathan C. and {van der Wel}, Casper M. and Verweij, Ruben W.},
 year = {2023},
 title = {soft-matter/trackpy: v0.6.1},
 publisher = {Zenodo},
 doi = {10.5281/zenodo.7670439}
}


@article{Bewley.2016,
 abstract = {This paper explores a pragmatic approach to multiple object tracking where the main focus is to associate objects efficiently for online and realtime applications. To this end, detection quality is identified as a key factor influencing tracking performance, where changing the detector can improve tracking by up to 18.9{\%}. Despite only using a rudimentary combination of familiar techniques such as the Kalman Filter and Hungarian algorithm for the tracking components, this approach achieves an accuracy comparable to state-of-the-art online trackers. Furthermore, due to the simplicity of our tracking method, the tracker updates at a rate of 260 Hz which is over 20x faster than other state-of-the-art trackers.},
 author = {Bewley, Alex and Ge, Zongyuan and Ott, Lionel and Ramos, Fabio and Upcroft, Ben},
 year = {2016},
 title = {Simple Online and Realtime Tracking},
 url = {http://arxiv.org/pdf/1602.00763v2},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 pages = {3464--3468},
 doi = {10.1109/ICIP.2016.7533003},
 file = {SORT:Attachments/SORT.pdf:application/pdf}
}


@book{Bishop.2006,
 author = {Bishop, Christopher M.},
 year = {2006},
 title = {Pattern recognition and machine learning},
 keywords = {Artificial intelligence;Machine learning;Pattern perception;Pattern recognition},
 address = {New York, NY},
 edition = {13.  (corrected at 8th printing 2009)},
 publisher = {Springer},
 isbn = {0-387-31073-8},
 series = {Computer science},
 file = {Bishop-Pattern-Recognition-and-Machine-Learning-2006:Attachments/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf:application/pdf}
}


@book{Boyd.2004,
 author = {Boyd, Stephen P. and Vandenberghe, Lieven},
 year = {2004},
 title = {Convex optimization},
 keywords = {Convex functions;Mathematical optimization},
 address = {New York, NY},
 edition = {7},
 publisher = {{Cambridge University Press}},
 isbn = {978-0-521-83378-3},
 institution = {{Cambridge University}},
 file = {Convex Optimization:Attachments/Convex Optimization.pdf:application/pdf}
}


@article{Breiman.2001,
 author = {Breiman, Leo},
 year = {2001},
 title = {Random Forests},
 pages = {5--32},
 number = {45},
 issn = {08856125},
 journal = {Machine Learning},
 doi = {10.1023/A:1010933404324},
 file = {randomforest2001:Attachments/randomforest2001.pdf:application/pdf;Breiman 2001 - Random Forest:Attachments/Breiman 2001 - Random Forest.pdf:application/pdf}
}


@book{Brownlee.2020,
 abstract = {Build predictive models from time-based patterns in your data. Master statistical models including new deep learning approaches for time series forecasting. In Time Series Forecasting in Python you will learn how to: Recognize a time series forecasting problem and build a performant predictive model Create univariate forecasting models that account for seasonal effects and external variables Build multivariate forecasting models to predict many time series at once Leverage large datasets by using deep learning for forecasting time series Automate the forecasting process Time Series Forecasting in Python teaches you to build powerful predictive models from time-based data. Every model you create is relevant, useful, and easy to implement with Python. You'll explore interesting real-world datasets like Google's daily stock price and economic data for the USA, quickly progressing from the basics to developing large-scale models that use deep learning tools like TensorFlow. About the Technology You can predict the future--with a little help from Python, deep learning, and time series data! Time series forecasting is a technique for modeling time-centric data to identify upcoming events. New Python libraries and powerful deep learning tools make accurate time series forecasts easier than ever before. About the Book Time Series Forecasting in Python teaches you how to get immediate, meaningful predictions from time-based data such as logs, customer analytics, and other event streams. In this accessible book, you'll learn statistical and deep learning methods for time series forecasting, fully demonstrated with annotated Python code. Develop your skills with projects like predicting the future volume of drug prescriptions, and you'll soon be ready to build your own accurate, insightful forecasts. What's Inside Create models for seasonal effects and external variables Multivariate forecasting models to predict multiple time series Deep learning for large datasets Automate the forecasting process About the Reader For data scientists familiar with Python and TensorFlow. About the Author Marco Peixeiro is a seasoned data science instructor who has worked as a data scientist for one of Canada's largest banks. Quotes The importance of time series analysis cannot be overstated. This book provides key techniques to deal with time series data in real-world applications. Indispensable. - Amaresh Rajasekharan, IBM Marco Peixeiro presents concepts clearly using interesting examples and illustrative plots. You'll be up and running quickly using the power of Python. - Ariel Andres, MD Financial Management What caught my attention were the practical examples immediately applicable to real life. He explains complex topics without the excess of mathematical formalism. - Simone Sguazza, University of Applied Sciences and Arts of Southern Switzerland.},
 author = {Brownlee, Jason},
 year = {2020},
 title = {Introduction to Time Series Forecasting with Python: How to Prepare Data and Develop Models to Predict the Future},
 keywords = {Computer programs;Data processing;Python (Computer program language);Time-series analysis},
 file = {introduction-to-time-series-forecasting-with-python:Attachments/introduction-to-time-series-forecasting-with-python.pdf:application/pdf}
}


@book{Burkov.2019,
 author = {Burkov, Andriy},
 year = {2019},
 title = {The hundred-page machine learning book},
 keywords = {Data processing;Machine learning;Materials science},
 address = {Polen},
 publisher = {{Andriy Burkov} and {Amazon Fulfillment}},
 isbn = {9781999579500},
 file = {TheHundred-pageMachineLearning:Attachments/TheHundred-pageMachineLearning.pdf:application/pdf}
}


@article{Chen.2023,
 abstract = {Chicken is a major source of dietary protein worldwide. The dispersion and movement of chickens constitute vital indicators of their health and status. This is especially evident in Taiwanese native chickens (TNCs), a local variety which is high in physical activity when healthy. Conventionally, the dispersion and movement of chicken flocks are observed in patrols. However, manual patrolling is laborious and time-consuming. Moreover, frequent patrols increase the risk of carrying pathogens into chicken farms. To address these issues, this study proposes an approach to develop an automatic warning system for anomalous dispersion and movement of chicken flocks in commercial chicken farms. Embendded systems were developed to acquire videos of chickens from overhead view in a chicken house, in which approximately 20,000 TNCs were raised for a period of 10 wk. Each video was 5-min in length. The videos were transmitted to a remote cloud server and were converted into images. A You Only Look Once-version 7 tiny (YOLOv7-tiny) object detection model was trained to detect chickens in the images. The dispersion of the chicken flocks in a 5-min long video was calculated using nearest neighbor index (NNI). The movement of the chicken flocks in a 5-min long video was quantified using simple online and real-time tracking algorithm (SORT). The normal ranges (i.e., 95{\%} confidence intervals) of chicken dispersion and movement were established using an autoregressive integrated moving average (ARIMA) model and a seasonal autoregressive integrated moving average with exogenous factors (SARIMAX) model, respectively. The system allows farmers to check up on the chicken farm only when the dispersion or movement values were not in the normal ranges. Thus, labor time can be saved and the risk of carrying pathogens into chicken farms can be reduced. The trained YOLOv7-tiny model achieved an average precision of 98.2{\%} in chicken detection. SORT achieved a multiple object tracking accuracy of 95.3{\%}. The ARIMA and SARIMAX achieved a mean absolute percentage error 3.71{\%} and 13.39{\%}, respectively, in forecasting dispersion and movement. The proposed approach can serve as a solution for automatic monitoring of anomalous chicken dispersion and movement in chicken farming, alerting farmers of potential health risks and environmental hazards in chicken farms.},
 author = {Chen, Bo-Lin and Cheng, Ting-Hui and Huang, Yi-Che and Hsieh, Yu-Lun and Hsu, Hao-Chun and Lu, Chen-Yi and Huang, Mao-Hsiang and Nien, Shu-Yao and Kuo, Yan-Fu},
 year = {2023},
 title = {Developing an automatic warning system for anomalous chicken dispersion and movement using deep learning and machine learning},
 keywords = {Animals;Chickens;Convolutional neural network (CNN);Deep Learning;Embedded system;Farmers;Farms;Humans;Simple online and real-time tracking (SORT);Taiwanese native chickens (TNCs);You only look once (YOLO)},
 pages = {103040},
 volume = {102},
 number = {12},
 journal = {Poultry science},
 doi = {10.1016/j.psj.2023.103040},
 file = {Developing an Automatic Warning System for Anomalous Chicken:Attachments/Developing an Automatic Warning System for Anomalous Chicken.pdf:application/pdf}
}


@article{CLEAR.2008,
 author = {Bernardin, Keni and Stiefelhagen, Rainer},
 year = {2008},
 title = {Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics},
 pages = {1--10},
 volume = {2008},
 issn = {1687-5176},
 journal = {EURASIP Journal on Image and Video Processing},
 doi = {10.1155/2008/246309},
 file = {The CLEAR MOT Metrics:Attachments/The CLEAR MOT Metrics.pdf:application/pdf}
}


@article{Crocker.1996,
 abstract = {Journal of Colloid and Interface Science},
 author = {Crocker, John C. and Grier, David G.},
 year = {1996},
 title = {Methods of Digital Video Microscopy for Colloidal Studies},
 keywords = {colloid;diffusion coefficient;dynamics;image processing;interaction potential;optical tweezers;video microscopy},
 pages = {298--310},
 volume = {179},
 number = {1},
 issn = {00219797},
 journal = {Journal of Colloid and Interface Science},
 doi = {10.1006/jcis.1996.0217},
 file = {Crocker Gier:Attachments/Crocker Gier.pdf:application/pdf}
}


@misc{DataFlair.2021-09-27,
 abstract = {Python Hadoop Spark Tableau Data Science},
 author = {DataFlair},
 year = {2021-09-27},
 title = {Blogs - DataFlair},
 url = {https://data-flair.training/blogs/},
 urldate = {2023-09-25}
}


@misc{Dendorfer.2020-10-15,
 abstract = {Standardized benchmarks have been crucial in pushing the performance of computer vision algorithms, especially since the advent of deep learning. Although leaderboards should not be over-claimed, they often provide the most objective measure of performance and are therefore important guides for research. We present MOTChallenge, a benchmark for single-camera Multiple Object Tracking (MOT) launched in late 2014, to collect existing and new data, and create a framework for the standardized evaluation of multiple object tracking methods. The benchmark is focused on multiple people tracking, since pedestrians are by far the most studied object in the tracking community, with applications ranging from robot navigation to self-driving cars. This paper collects the first three releases of the benchmark: (i) MOT15, along with numerous state-of-the-art results that were submitted in the last years, (ii) MOT16, which contains new challenging videos, and (iii) MOT17, that extends MOT16 sequences with more precise labels and evaluates tracking performance on three different object detectors. The second and third release not only offers a significant increase in the number of labeled boxes but also provide labels for multiple object classes beside pedestrians, as well as the level of visibility for every single object of interest. We finally provide a categorization of state-of-the-art trackers and a broad error analysis. This will help newcomers understand the related work and research trends in the MOT community, and hopefully shed some light on potential future research directions.},
 author = {Dendorfer, Patrick and O{\v{s}}ep, Aljo{\v{s}}a and Milan, Anton and Schindler, Konrad and Cremers, Daniel and Reid, Ian and Roth, Stefan and Leal-Taix{\'e}, Laura},
 date = {2020-10-15},
 title = {MOTChallenge: A Benchmark for Single-Camera Multiple Target Tracking},
 url = {http://arxiv.org/pdf/2010.07548v2},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 file = {MOTchellange:Attachments/MOTchellange.pdf:application/pdf}
}


@book{Goodfellow.2016,
 author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
 year = {2016},
 title = {Deep learning},
 price = {Hardcover : GBP 66.95},
 keywords = {Machine learning},
 address = {Cambridge, Massachusetts and London, England},
 publisher = {{The MIT Press}},
 isbn = {0262035618},
 series = {Adaptive computation and machine learning},
 institution = {{MIT Press}},
 file = {Deep Learning Ian Goodfellow, Yoshua Bengio, Aaron Courville:Attachments/Deep Learning Ian Goodfellow, Yoshua Bengio, Aaron Courville.pdf:application/pdf}
}


@article{Guyon.2003,
 author = {Guyon, Isabelle and Ellisseeff, Andr{\'e}},
 year = {2003},
 title = {An Introduction to Variable and Feature Selection},
 url = {https://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf},
 pages = {1157--1182},
 number = {3},
 journal = {Journal of Machine Learning Reserch},
 file = {An Introduction to Variable 2003:Attachments/An Introduction to Variable 2003.pdf:application/pdf}
}


@article{HOTA,
 abstract = {Multi-Object Tracking (MOT) has been notoriously difficult to evaluate. Previous metrics overemphasize the importance of either detection or association. To address this, we present a novel MOT evaluation metric, HOTA (Higher Order Tracking Accuracy), which explicitly balances the effect of performing accurate detection, association and localization into a single unified metric for comparing trackers. HOTA decomposes into a family of sub-metrics which are able to evaluate each of five basic error types separately, which enables clear analysis of tracking performance. We evaluate the effectiveness of HOTA on the MOTChallenge benchmark, and show that it is able to capture important aspects of MOT performance not previously taken into account by established metrics. Furthermore, we show HOTA scores better align with human visual evaluation of tracking performance.},
 author = {Luiten, Jonathon and Osep, Aljosa and Dendorfer, Patrick and Torr, Philip and Geiger, Andreas and Leal-Taixe, Laura and Leibe, Bastian},
 year = {2020},
 title = {HOTA: A Higher Order Metric for Evaluating Multi-Object Tracking},
 url = {http://arxiv.org/pdf/2009.07736v2},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 pages = {548--578},
 volume = {129},
 number = {2},
 issn = {0920-5691},
 journal = {International Journal of Computer Vision},
 doi = {10.1007/s11263-020-01375-2},
 file = {HOTA A Higher Order Metric for Evaluating Multi-Object Tracking:Attachments/HOTA A Higher Order Metric for Evaluating Multi-Object Tracking.pdf:application/pdf}
}


@misc{IDF1,
 abstract = {To help accelerate progress in multi-target, multi-camera tracking systems, we present (i) a new pair of precision-recall measures of performance that treats errors of all types uniformly and emphasizes correct identification over sources of error; (ii) the largest fully-annotated and calibrated data set to date with more than 2 million frames of 1080p, 60fps video taken by 8 cameras observing more than 2,700 identities over 85 minutes; and (iii) a reference software system as a comparison baseline. We show that (i) our measures properly account for bottom-line identity match performance in the multi-camera setting; (ii) our data set poses realistic challenges to current trackers; and (iii) the performance of our system is comparable to the state of the art.},
 author = {Ristani, Ergys and Solera, Francesco and Zou, Roger S. and Cucchiara, Rita and Tomasi, Carlo},
 date = {2016-09-06},
 title = {Performance Measures and a Data Set for Multi-Target, Multi-Camera  Tracking},
 url = {http://arxiv.org/pdf/1609.01775.pdf},
 file = {Ristani, Solera et al. 2016-09-06 - Performance Measures and a Data:Attachments/Ristani, Solera et al. 2016-09-06 - Performance Measures and a Data.pdf:application/pdf}
}


@proceedings{InstituteofElectricalandElectronicsEngineers.2013,
 year = {2013},
 title = {2013 IEEE Conference on Computer Vision and Pattern Recognition workshops (CVPRW 2013): Portland, Oregon, USA, 23 - 28 June 2013 ; [proceedings},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-0-7695-4990-3},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE Computer Society}}
}


@inproceedings{JohnS.Garofolo.2006,
 author = {{John S. Garofolo} and {Rachel Bowers} and {Dennis E. Moellman} and {Rangachar Kasturi} and {Dmitry Goldgof} and {Padmanabhan Soundararajan}},
 title = {PERFORMANCE EVALUATION PROTOCOL FOR FACE, PERSON AND VEHICLE DETECTION {\&} TRACKING IN VIDEO ANALYSIS AND CONTENT EXTRACTION (VACE-II) CLEAR - CLASSIFICATION OF EVENTS, ACTIVITIES AND RELATIONSHIPS},
 url = {https://api.semanticscholar.org/CorpusID:130025156},
 year = {2006},
 file = {ClearEval{\_}Protocol{\_}v5:Attachments/ClearEval{\_}Protocol{\_}v5.pdf:application/pdf}
}


@article{Kalman.1960,
 author = {Kalman, R. E.},
 year = {1960},
 title = {A New Approach to Linear Filtering and Prediction Problems},
 pages = {35--45},
 volume = {82},
 number = {1},
 issn = {0021-9223},
 journal = {Journal of Basic Engineering},
 doi = {10.1115/1.3662552}
}


@article{Kasturi.2009,
 abstract = {Common benchmark data sets, standardized performance metrics, and baseline algorithms have demonstrated considerable impact on research and development in a variety of application domains. These resources provide both consumers and developers of technology with a common framework to objectively compare the performance of different algorithms and algorithmic improvements. In this paper, we present such a framework for evaluating object detection and tracking in video: specifically for face, text, and vehicle objects. This framework includes the source video data, ground-truth annotations (along with guidelines for annotation), performance metrics, evaluation protocols, and tools including scoring software and baseline algorithms. For each detection and tracking task and supported domain, we developed a 50-clip training set and a 50-clip test set. Each data clip is approximately 2.5 minutes long and has been completely spatially/temporally annotated at the I-frame level. Each task/domain, therefore, has an associated annotated corpus of approximately 450,000 frames. The scope of such annotation is unprecedented and was designed to begin to support the necessary quantities of data for robust machine learning approaches, as well as a statistically significant comparison of the performance of algorithms. The goal of this work was to systematically address the challenges of object detection and tracking through a common evaluation framework that permits a meaningful objective comparison of techniques, provides the research community with sufficient data for the exploration of automatic modeling techniques, encourages the incorporation of objective evaluation into the development process, and contributes useful lasting resources of a scale and magnitude that will prove to be extremely useful to the computer vision research community for years to come.},
 author = {Kasturi, Rangachar and Goldgof, Dmitry and Soundararajan, Padmanabhan and Manohar, Vasant and Garofolo, John and Bowers, Rachel and Boonstra, Matthew and Korzhova, Valentina and Zhang, Jing},
 year = {2009},
 title = {Framework for performance evaluation of face, text, and vehicle detection and tracking in video: data, metrics, and protocol},
 keywords = {Algorithms;Artificial intelligence;Electronic Data Processing;Face/anatomy {\&} histology;Humans;Image Enhancement/methods;Image Interpretation, Computer-Assisted/methods;Motor Vehicles/classification;Pattern Recognition, Automated/methods;Sensitivity and Specificity;Subtraction Technique;Video Recording/methods},
 pages = {319--336},
 volume = {31},
 number = {2},
 journal = {IEEE transactions on pattern analysis and machine intelligence},
 doi = {10.1109/TPAMI.2008.57},
 file = {Framework{\_}for{\_}Performance{\_}Evaluation{\_}of{\_}Face{\_}Text{\_}and{\_}Vehicle{\_}Detection{\_}and{\_}Tracking{\_}in{\_}Video{\_}Data{\_}Metrics{\_}and{\_}Protocol:Attachments/Framework{\_}for{\_}Performance{\_}Evaluation{\_}of{\_}Face{\_}Text{\_}and{\_}Vehicle{\_}Detection{\_}and{\_}Tracking{\_}in{\_}Video{\_}Data{\_}Metrics{\_}and{\_}Protocol.pdf:application/pdf}
}


@book{Kroschel.2011,
 author = {Kroschel, Kristian and Rigoll, Gerhard and Schuller, Bj{\"o}rn},
 year = {2011},
 title = {Statistische Informationstechnik},
 address = {Berlin, Heidelberg},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-642-15953-4},
 doi = {10.1007/978-3-642-15954-1},
 file = {Statistische Informationstechnik:Attachments/Statistische Informationstechnik.pdf:application/pdf}
}


@article{Kuhn.1955,
 author = {Kuhn, Harold W.},
 year = {1955},
 title = {The Hungarian method for the assignment problem},
 volume = {52},
 journal = {Naval Research Logistics (NRL)},
 file = {Kuhn-hungarian-assignment:Attachments/Kuhn-hungarian-assignment.pdf:application/pdf}
}


@book{Kuhn.2013,
 author = {Kuhn, Max and Johnson, Kjell},
 year = {2013},
 title = {Applied Predictive Modeling},
 address = {New York, NY},
 publisher = {{Springer New York}},
 isbn = {978-1-4614-6848-6},
 doi = {10.1007/978-1-4614-6849-3},
 file = {applied-predictive-modeling-max-kuhn-kjell-johnson{\_}1518:Attachments/applied-predictive-modeling-max-kuhn-kjell-johnson{\_}1518.pdf:application/pdf}
}


@book{Lazzeri.2021,
 abstract = {Cover -- Title Page -- Copyright -- About the Author -- About the Technical Editor -- Acknowledgments -- Contents at a Glance -- Contents -- Introduction -- Chapter 1 Overview of~Time Series Forecasting -- Flavors of~Machine Learning for~Time Series Forecasting -- Supervised Learning for~Time Series Forecasting -- Python for~Time Series Forecasting -- Experimental Setup for~Time Series Forecasting -- Conclusion -- Chapter 2 How to~Design an~End-to-End Time Series Forecasting Solution on~the~Cloud -- Time Series Forecasting Template -- Business Understanding and~Performance Metrics -- Data Ingestion -- Data Exploration and~Understanding -- Data Pre-processing and~Feature Engineering -- Modeling Building and~Selection -- An Overview of~Demand Forecasting Modeling Techniques -- Model Evaluation -- Model Deployment -- Forecasting Solution Acceptance -- Use Case: Demand Forecasting -- Conclusion -- Chapter 3 Time Series Data Preparation -- Python for~Time Series Data -- Common Data Preparation Operations for~Time Series -- Time stamps vs. Periods -- Converting to~Time stamps -- Providing a~Format Argument -- Indexing -- Time/Date Components -- Frequency Conversion -- Time Series Exploration and~Understanding -- How to~Get Started with~Time Series Data Analysis -- Data Cleaning of~Missing Values in~the~Time Series -- Time Series Data Normalization and~Standardization -- Time Series Feature Engineering -- Date Time Features -- Lag Features and~Window Features -- Rolling Window Statistics -- Expanding Window Statistics -- Conclusion -- Chapter 4 Introduction to~Autoregressive and~Automated Methods for~Time Series Forecasting -- Autoregression -- Moving Average -- Autoregressive Moving Average -- Autoregressive Integrated Moving Average -- Automated Machine Learning -- Conclusion -- Chapter 5 Introduction to~Neural Networks for~Time Series Forecasting.},
 author = {Lazzeri, Francesca},
 year = {2021},
 title = {Machine Learning for Time Series Forecasting with Python},
 keywords = {Electronic books;Machine learning;Python (Computer program language)},
 address = {Newark},
 publisher = {{John Wiley {\&} Sons Incorporated}},
 isbn = {978-1-119-68236-3},
 file = {Machine Learning for Time Series Forecasting:Attachments/Machine Learning for Time Series Forecasting.pdf:application/pdf}
}


@article{Leichter.2013,
 abstract = {There exists an abundance of systems and algorithms for multiple target detection and tracking in video, and many measures for evaluating the quality of their output have been proposed. The contribution of this paper lies in the following: first, it argues that such performance measures should have two fundamental properties--monotonicity and error type differentiability; second, it shows that the recently proposed measures do not have either of these properties and are, thus, less usable; third, it composes a set of simple measures, partly built on common practice, that does have these properties. The informativeness of the proposed set of performance measures is demonstrated through their application on face detection and tracking results.},
 author = {Leichter, Ido and Krupka, Eyal},
 year = {2013},
 title = {Monotonicity and error type differentiability in performance measures for target detection and tracking in video},
 pages = {2553--2560},
 volume = {35},
 number = {10},
 journal = {IEEE transactions on pattern analysis and machine intelligence},
 doi = {10.1109/TPAMI.2013.70},
 file = {Monotonicity and Error Type Differentiability:Attachments/Monotonicity and Error Type Differentiability.pdf:application/pdf}
}


@misc{Luo.2022,
 abstract = {Multiple Object Tracking (MOT) has gained increasing attention due to its academic and commercial potential. Although different approaches have been proposed to tackle this problem, it still remains challenging due to factors like abrupt appearance changes and severe object occlusions. In this work, we contribute the first comprehensive and most recent review on this problem. We inspect the recent advances in various aspects and propose some interesting directions for future research. To the best of our knowledge, there has not been any extensive review on this topic in the community. We endeavor to provide a thorough review on the development of this problem in recent decades. The main contributions of this review are fourfold: 1) Key aspects in an MOT system, including formulation, categorization, key principles, evaluation of MOT are discussed; 2) Instead of enumerating individual works, we discuss existing approaches according to various aspects, in each of which methods are divided into different groups and each group is discussed in detail for the principles, advances and drawbacks; 3) We examine experiments of existing publications and summarize results on popular datasets to provide quantitative and comprehensive comparisons. By analyzing the results from different perspectives, we have verified some basic agreements in the field; and 4) We provide a discussion about issues of MOT research, as well as some interesting directions which will become potential research effort in the future.

Accepted by Artificial Intelligence},
 author = {Luo, Wenhan and Xing, Junliang and Milan, Anton and Zhang, Xiaoqin and Liu, Wei and Kim, Tae-Kyun},
 date = {2022},
 title = {Multiple Object Tracking: A Literature Review},
 url = {http://arxiv.org/pdf/1409.7618.pdf},
 publisher = {arXiv},
 originalyear = {2014},
 file = {Multiple Object Tracking A Literature Review:Attachments/Multiple Object Tracking A Literature Review.pdf:application/pdf}
}


@book{McKinney.2013,
 author = {McKinney, Wes},
 year = {2013},
 title = {Python for data analysis},
 keywords = {Data mining;Programming languages (Electronic computers);Python (Computer program language)},
 address = {Beijing},
 publisher = {O'Reilly},
 isbn = {9781449319793},
 file = {Python-for-Data-Analysis:Attachments/Python-for-Data-Analysis.pdf:application/pdf}
}


@inproceedings{Milan.2013,
 author = {Milan, Anton and Schindler, Konrad and Roth, Stefan},
 title = {Challenges of Ground Truth Evaluation of Multi-target Tracking},
 pages = {735--742},
 publisher = {IEEE},
 isbn = {978-0-7695-4990-3},
 booktitle = {2013 IEEE Conference on Computer Vision and Pattern Recognition workshops (CVPRW 2013)},
 year = {2013},
 address = {Piscataway, NJ},
 doi = {10.1109/CVPRW.2013.111},
 file = {Milan{\_}Challenges{\_}of{\_}Ground{\_}2013{\_}CVPR{\_}paper:Attachments/Milan{\_}Challenges{\_}of{\_}Ground{\_}2013{\_}CVPR{\_}paper.pdf:application/pdf;Challenges{\_}of{\_}Ground{\_}Truth{\_}Evaluation{\_}of{\_}Multi-target{\_}Tracking:Attachments/Challenges{\_}of{\_}Ground{\_}Truth{\_}Evaluation{\_}of{\_}Multi-target{\_}Tracking.pdf:application/pdf}
}


@misc{MOT15,
 abstract = {In the recent past, the computer vision community has developed centralized benchmarks for the performance evaluation of a variety of tasks, including generic object and pedestrian detection, 3D reconstruction, optical flow, single-object short-term tracking, and stereo estimation. Despite potential pitfalls of such benchmarks, they have proved to be extremely helpful to advance the state of the art in the respective area. Interestingly, there has been rather limited work on the standardization of quantitative benchmarks for multiple target tracking. One of the few exceptions is the well-known PETS dataset, targeted primarily at surveillance applications. Despite being widely used, it is often applied inconsistently, for example involving using different subsets of the available data, different ways of training the models, or differing evaluation scripts. This paper describes our work toward a novel multiple object tracking benchmark aimed to address such issues. We discuss the challenges of creating such a framework, collecting existing and new data, gathering state-of-the-art methods to be tested on the datasets, and finally creating a unified evaluation system. With MOTChallenge we aim to pave the way toward a unified evaluation framework for a more meaningful quantification of multi-target tracking.},
 author = {Leal-Taix{\'e}, Laura and Milan, Anton and Reid, Ian and Roth, Stefan and Schindler, Konrad},
 date = {2015-04-08},
 title = {MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking},
 url = {http://arxiv.org/pdf/1504.01942v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 file = {MOT15:Attachments/MOT15.pdf:application/pdf}
}


@misc{MOT16,
 abstract = {Standardized benchmarks are crucial for the majority of computer vision applications. Although leaderboards and ranking tables should not be over-claimed, benchmarks often provide the most objective measure of performance and are therefore important guides for reseach.  Recently, a new benchmark for Multiple Object Tracking, MOTChallenge, was launched with the goal of collecting existing and new data and creating a framework for the standardized evaluation of multiple object tracking methods. The first release of the benchmark focuses on multiple people tracking, since pedestrians are by far the most studied object in the tracking community. This paper accompanies a new release of the MOTChallenge benchmark. Unlike the initial release, all videos of MOT16 have been carefully annotated following a consistent protocol. Moreover, it not only offers a significant increase in the number of labeled boxes, but also provides multiple object classes beside pedestrians and the level of visibility for every single object of interest.},
 author = {Milan, Anton and Leal-Taixe, Laura and Reid, Ian and Roth, Stefan and Schindler, Konrad},
 date = {2016-03-02},
 title = {MOT16: A Benchmark for Multi-Object Tracking},
 url = {http://arxiv.org/pdf/1603.00831v2},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 file = {MOT16:Attachments/MOT16.pdf:application/pdf}
}


@misc{MOT20,
 abstract = {Standardized benchmarks are crucial for the majority of computer vision applications. Although leaderboards and ranking tables should not be over-claimed, benchmarks often provide the most objective measure of performance and are therefore important guides for research. The benchmark for Multiple Object Tracking, MOTChallenge, was launched with the goal to establish a standardized evaluation of multiple object tracking methods. The challenge focuses on multiple people tracking, since pedestrians are well studied in the tracking community, and precise tracking and detection has high practical relevance. Since the first release, MOT15, MOT16, and MOT17 have tremendously contributed to the community by introducing a clean dataset and precise framework to benchmark multi-object trackers. In this paper, we present our MOT20benchmark, consisting of 8 new sequences depicting very crowded challenging scenes. The benchmark was presented first at the 4thBMTT MOT Challenge Workshop at the Computer Vision and Pattern Recognition Conference (CVPR) 2019, and gives to chance to evaluate state-of-the-art methods for multiple object tracking when handling extremely crowded scenarios.},
 author = {Dendorfer, Patrick and Rezatofighi, Hamid and Milan, Anton and Shi, Javen and Cremers, Daniel and Reid, Ian and Roth, Stefan and Schindler, Konrad and Leal-Taix{\'e}, Laura},
 date = {2020-03-19},
 title = {MOT20: A benchmark for multi object tracking in crowded scenes},
 url = {http://arxiv.org/pdf/2003.09003v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 file = {MOT20:Attachments/MOT20.pdf:application/pdf}
}


@book{Nelson.1972,
 author = {Nelson, Edward},
 year = {1972},
 title = {Dynamical theories of Brownian motion},
 address = {Princeton, NJ},
 publisher = {{Princeton Univ. Pr}},
 isbn = {9780691079509},
 series = {Mathematical notes},
 file = {bmotion:Attachments/bmotion.pdf:application/pdf}
}


@book{Ng.2018,
 author = {Ng, Andrew},
 year = {2018},
 title = {Machine Learning Yearning: Technical Strategy for AI Engineers, in the Era of Deep Learning},
 institution = {deeplearning.ai},
 file = {machine-learning-yearning:Attachments/machine-learning-yearning.pdf:application/pdf}
}


@book{Nielsen.2020,
 author = {Nielsen, Aileen},
 year = {2020},
 title = {Practical time series analysis: Prediction with statistics and machine learning},
 address = {Beijing and Boston and Farnham and Sebastopol and Tokyo},
 edition = {First edition},
 publisher = {O'Reilly},
 isbn = {9781492041658},
 doi = {Aileen},
 file = {practical-time-series-analysis-prediction-with-statistics-and-machine-learning:Attachments/practical-time-series-analysis-prediction-with-statistics-and-machine-learning.pdf:application/pdf}
}


@misc{Ristani.2016-09-06b,
 abstract = {To help accelerate progress in multi-target, multi-camera tracking systems, we present (i) a new pair of precision-recall measures of performance that treats errors of all types uniformly and emphasizes correct identification over sources of error; (ii) the largest fully-annotated and calibrated data set to date with more than 2 million frames of 1080p, 60fps video taken by 8 cameras observing more than 2,700 identities over 85 minutes; and (iii) a reference software system as a comparison baseline. We show that (i) our measures properly account for bottom-line identity match performance in the multi-camera setting; (ii) our data set poses realistic challenges to current trackers; and (iii) the performance of our system is comparable to the state of the art.},
 author = {Ristani, Ergys and Solera, Francesco and Zou, Roger S. and Cucchiara, Rita and Tomasi, Carlo},
 date = {2016-09-06},
 title = {Performance Measures and a Data Set for Multi-Target, Multi-Camera  Tracking},
 url = {http://arxiv.org/pdf/1609.01775v2},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 file = {IDF1:Attachments/IDF1.pdf:application/pdf}
}


@phdthesis{Roelofsen.2018,
 author = {Roelofsen, Pjotr},
 year = {2018},
 title = {Time series clustering},
 url = {https://perma.cc/K8HJ-7FFE},
 address = {Amsterdam},
 publisher = {Faculty of Science},
 school = {{Vrije Universiteit Amsterdam}},
 type = {Masterarbeit},
 file = {Time series clustering - Pjotr Roelofsen:Attachments/Time series clustering - Pjotr Roelofsen.pdf:application/pdf}
}


@misc{scikitlearn.2023-09-25,
 abstract = {User Guide: Supervised learning- Linear Models- Ordinary Least Squares, Ridge regression and classification, Lasso, Multi-task Lasso, Elastic-Net, Multi-task Elastic-Net, Least Angle Regression, LA...},
 author = {scikit-learn},
 year = {2023-09-25},
 title = {User guide: contents},
 url = {https://scikit-learn.org/stable/user_guide.html},
 urldate = {2023-09-25}
}


@misc{scikitlearn.2023-09-25b,
 abstract = {Often the hardest part of solving a machine learning problem can be finding the right estimator for the job. Different estimators are better suited for different types of data and different problem...},
 author = {scikit-learn},
 year = {2023-09-25},
 title = {Choosing the right estimator},
 url = {https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html},
 urldate = {2023-09-25}
}


@book{ShalevShwartz.2014,
 abstract = {{\textquotedbl}Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering{\textquotedbl}--},
 author = {Shalev-Shwartz, Shai and Ben-David, Shai},
 year = {2014},
 title = {Understanding machine learning: From theory to algorithms},
 keywords = {Algorithms;COMPUTERS / Computer Vision {\&} Pattern Recognition;Machine learning},
 address = {New York NY  USA},
 publisher = {{Cambridge University Press}},
 isbn = {9781107057135},
 file = {understanding-machine-learning-theory-algorithms:Attachments/understanding-machine-learning-theory-algorithms.pdf:application/pdf}
}


@phdthesis{Soleymani.2016,
 author = {Soleymani, Ali},
 year = {2016},
 title = {Cross-Scale  Analysis in Classification and Segmentation of Movement},
 address = {Z{\"u}rich},
 publisher = {Mathematisch-naturwissenschaftlichen Fakult{\"a}t},
 school = {{Universit{\"a}t Z{\"u}rich}},
 type = {Dissertation},
 file = {Cross-Scale  Analysis in Classification and Segmentation of Movement:Attachments/Cross-Scale  Analysis in Classification and Segmentation of Movement.pdf:application/pdf}
}


@misc{Sutton.2010-11-17,
 abstract = {Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.},
 author = {Sutton, Charles and McCallum, Andrew},
 date = {2010-11-17},
 title = {An Introduction to Conditional Random Fields},
 url = {http://arxiv.org/pdf/1011.4088v1},
 keywords = {Statistics - Machine Learning},
 doi = {pages},
 file = {An Introduction to Conditional Random Fields - Charles Sutton:Attachments/An Introduction to Conditional Random Fields - Charles Sutton.pdf:application/pdf}
}


@book{Turabian.2018,
 abstract = {This new edition of the classic reference work on writing research papers recognizes recent developments in information literacy--including finding, evaluating, and citing a wide range of digital sources--and the evolving use of software for citation management, graphics, and paper format and submission while continuing to reflect best practices for research and writing, as adapted from the most recent editions of The Craft of Research and The Chicago Manual of Style. (Provided by publisher)},
 author = {Turabian, Kate L.},
 year = {2018},
 title = {A manual for writers of research papers, theses, and dissertations: Chicago Style for students and researchers},
 keywords = {Academic writing;Dissertations, Academic;Handbooks and manuals;Handbooks, manuals, etc;LANGUAGE ARTS {\&} DISCIPLINES;REF028000 Reference / Handbooks {\&} Manuals;Study {\&} learning skills: general},
 address = {Chicago and London},
 edition = {9th edition},
 publisher = {{The University of Chicago Press}},
 isbn = {978-0226494425},
 series = {Chicago guides to writing, editing, and publishing},
 institution = {{University of Chicago Press}},
 file = {turabian{\_}manual{\_}9th{\_}ed:Attachments/turabian{\_}manual{\_}9th{\_}ed.pdf:application/pdf}
}


@article{Tzini.2020-12-03,
 abstract = {This post is the second part of a blog series on Feature Selection. Have a look at Filter (part1) and Embedded (part3) Methods. In part 1, we talked about Filter methods, which help you select$\ldots$},
 author = {Tzini, Elli},
 year = {2020-12-03},
 title = {Feature Selection: Wrapper Methods | Analytics Vidhya},
 url = {https://medium.com/analytics-vidhya/feature-selection-85539d6a2a88},
 urldate = {2023-12-15},
 journal = {Analytics Vidhya}
}


@phdthesis{Vollmer.2016,
 author = {Vollmer, Christian},
 title = {Weiterentwicklung und Anwendung von Sparse-Coding-Verfahren f{\"u}r die Analyse von Armbewegungstrajektorien},
 address = {Ilmenau},
 publisher = {Fakult{\"a}t f{\"u}r Informatik und Automatisierung},
 school = {{Technischen Universit{\"a}t Ilmenau}},
 type = {Dissertation},
 file = {Weiterentwicklung und Anwendung von Sparse-Coding-Verfahren f{\"u}r die ANalyse von Armbewegungstrajektorien:Attachments/Weiterentwicklung und Anwendung von Sparse-Coding-Verfahren f{\"u}r die ANalyse von Armbewegungstrajektorien.pdf:application/pdf}
}


@book{Zheng.2015,
 author = {Zheng, Alice},
 year = {2015},
 title = {Evaluating machine learning models: A beginner's guide to key concepts and pitfalls},
 keywords = {Apprentissage automatique;Machine learning},
 address = {Sebastopol, Calif.},
 edition = {September 2015, First edition},
 publisher = {{O'Reilly Media}},
 isbn = {978-1-491-93246-9},
 file = {Evaluating Machine Learning Models:Attachments/Evaluating Machine Learning Models.pdf:application/pdf}
}


@book{Zheng.2018,
 abstract = {Feature engineering is a crucial step in the machine-learning pipeline, yet this topic is rarely examined on its own. With this practical book, youll learn techniques for extracting and transforming featuresthe numeric representations of raw datainto formats for machine-learning models. Each chapter guides you through a single data problem, such as how to represent text or image data. Together, these examples illustrate the main principles of feature engineering.--},
 author = {Zheng, Alice and Casari, Amanda},
 year = {2018},
 title = {Feature engineering for machine learning: Principles and techniques for data scientists},
 keywords = {Data mining;Machine learning},
 address = {Beijing and Boston},
 edition = {First edition},
 publisher = {O'Reilly},
 isbn = {9781491953242},
 file = {feature{\_}engineering{\_}for{\_}machine{\_}learning:Attachments/feature{\_}engineering{\_}for{\_}machine{\_}learning.pdf:application/pdf}
}


